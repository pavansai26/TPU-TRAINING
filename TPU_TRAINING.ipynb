{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBTZ/64iIp6EPxaZbuwCdM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavansai26/TPU-TRAINING/blob/main/TPU_TRAINING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup"
      ],
      "metadata": {
        "id": "DUPmqFpU9EAn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before you run this Colab notebook, make sure that your hardware accelerator is a TPU by checking your notebook settings: Runtime > Change runtime type > Hardware accelerator > TPU."
      ],
      "metadata": {
        "id": "AePIR8OO9HeZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import some necessary libraries"
      ],
      "metadata": {
        "id": "CPzK5cRT9P4Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IvObgRf88s_j"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TPU initialization"
      ],
      "metadata": {
        "id": "2GnPPcf6GaIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TPUs are typically Cloud TPU workers, which are different from the local process running the user's Python program."
      ],
      "metadata": {
        "id": "XA65pSKtGnuf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus, you need to do some initialization work to connect to the remote cluster and initialize the TPUs. Note that the tpu argument to tf.distribute.cluster_resolver.TPUClusterResolver is a special address just for Colab."
      ],
      "metadata": {
        "id": "x8AhOrSiGsnH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: The TPU initialization code has to be at the beginning of your program.\n"
      ],
      "metadata": {
        "id": "lcVqGXaXHImc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PysXk_FGR8q",
        "outputId": "04b71e20-dd33-4c3a-d6ab-cb8ab6d68194"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "device placement"
      ],
      "metadata": {
        "id": "aXft2B0VHR24"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the TPU is initialized, you can use manual device placement to place the computation on a single TPU device"
      ],
      "metadata": {
        "id": "QyayBjDmHVby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "\n",
        "with tf.device('/TPU:0'):\n",
        "  c = tf.matmul(a, b)\n",
        "\n",
        "print(\"c device: \", c.device)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cz8FUCWG8-P",
        "outputId": "037a18fb-3ed6-4600-c26e-8ab8f0f507e5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c device:  /job:worker/replica:0/task:0/device:TPU:0\n",
            "tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribution strategies"
      ],
      "metadata": {
        "id": "vF01T2pSH3YU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usually, you run your model on multiple TPUs in a data-parallel way. To distribute your model on multiple TPUs (as well as multiple GPUs or multiple machines), TensorFlow offers the tf.distribute.Strategy API."
      ],
      "metadata": {
        "id": "b_6QNSTUH8hY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the tf.distribute.TPUStrategy option implements synchronous distributed training."
      ],
      "metadata": {
        "id": "V03NIUIuITKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.TPUStrategy(resolver)\n",
        "strategy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QdfCoLKHiWT",
        "outputId": "e113d665-a6fb-4f13-c140-074d3fbb70eb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.distribute.tpu_strategy.TPUStrategyV2 at 0x7fa2738d2f40>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification on TPUs"
      ],
      "metadata": {
        "id": "Iro8JZgxJPEn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section demonstrates how to use the distribution strategy—tf.distribute.TPUStrategy—to train a Keras model on a Cloud TPU."
      ],
      "metadata": {
        "id": "KreJ5CPOJZ4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(batch_size, is_training=True):\n",
        "  split = 'train' if is_training else 'test'\n",
        "  dataset, info = tfds.load(name='mnist', split=split, with_info=True,\n",
        "                            as_supervised=True, try_gcs=True)\n",
        "\n",
        "  # Normalize the input data.\n",
        "  def scale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255.0\n",
        "    return image, label\n",
        "\n",
        "  dataset = dataset.map(scale)\n",
        "\n",
        "  # Only shuffle and repeat the dataset in training. The advantage of having an\n",
        "  # infinite dataset for training is to avoid the potential last partial batch\n",
        "  # in each epoch, so that you don't need to think about scaling the gradients\n",
        "  # based on the actual batch size.\n",
        "  if is_training:\n",
        "    dataset = dataset.shuffle(10000)\n",
        "    dataset = dataset.repeat()\n",
        "\n",
        "  dataset = dataset.batch(batch_size)\n",
        "\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "aQtOoOjpIYx2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start with a definition of a Sequential Keras model for image classification on the MNIST dataset. It's no different than what you would use if you were training on CPUs"
      ],
      "metadata": {
        "id": "DfwZHZJPM4g7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that Keras model creation needs to be inside the Strategy.scope, so the variables can be created on each TPU device. Other parts of the code are not necessary to be inside the Strategy scope."
      ],
      "metadata": {
        "id": "PMD7F-sfNA5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  return tf.keras.Sequential(\n",
        "      [tf.keras.layers.Conv2D(256, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "       tf.keras.layers.Conv2D(256, 3, activation='relu'),\n",
        "       tf.keras.layers.Flatten(),\n",
        "       tf.keras.layers.Dense(256, activation='relu'),\n",
        "       tf.keras.layers.Dense(128, activation='relu'),\n",
        "       tf.keras.layers.Dense(10)])"
      ],
      "metadata": {
        "id": "5rR96kN2L5wT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model using Keras high-level APIs"
      ],
      "metadata": {
        "id": "SeAF01AFLjjz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can train your model with Keras Model.fit and Model.compile APIs. There is nothing TPU-specific"
      ],
      "metadata": {
        "id": "R97C8Bs0Lqdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "batch_size = 200\n",
        "steps_per_epoch = 60000 // batch_size\n",
        "validation_steps = 10000 // batch_size\n",
        "\n",
        "train_dataset = get_dataset(batch_size, is_training=True)\n",
        "test_dataset = get_dataset(batch_size, is_training=False)\n",
        "\n",
        "model.fit(train_dataset,\n",
        "          epochs=5,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          validation_data=test_dataset,\n",
        "          validation_steps=validation_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn_Og_ZnLdB_",
        "outputId": "898c93b6-2cea-4f29-96fb-5e139c85caa1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "300/300 [==============================] - 21s 43ms/step - loss: 0.1390 - sparse_categorical_accuracy: 0.9565 - val_loss: 0.0547 - val_sparse_categorical_accuracy: 0.9835\n",
            "Epoch 2/5\n",
            "300/300 [==============================] - 10s 34ms/step - loss: 0.0335 - sparse_categorical_accuracy: 0.9901 - val_loss: 0.0439 - val_sparse_categorical_accuracy: 0.9865\n",
            "Epoch 3/5\n",
            "300/300 [==============================] - 10s 35ms/step - loss: 0.0194 - sparse_categorical_accuracy: 0.9938 - val_loss: 0.0401 - val_sparse_categorical_accuracy: 0.9881\n",
            "Epoch 4/5\n",
            "300/300 [==============================] - 11s 37ms/step - loss: 0.0117 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0511 - val_sparse_categorical_accuracy: 0.9855\n",
            "Epoch 5/5\n",
            "300/300 [==============================] - 11s 35ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0644 - val_sparse_categorical_accuracy: 0.9843\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa239964c70>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To reduce Python overhead and maximize the performance of your TPU, pass in the steps_per_execution argument to Keras Model.compile. In this example, it increases throughput by about 50%:"
      ],
      "metadata": {
        "id": "VsVkreYuMHQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "  model.compile(optimizer='adam',\n",
        "                # Anything between 2 and `steps_per_epoch` could help here.\n",
        "                steps_per_execution = 50,\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "model.fit(train_dataset,\n",
        "          epochs=5,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          validation_data=test_dataset,\n",
        "          validation_steps=validation_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ng3EmhM_LyIl",
        "outputId": "8c103b2e-aee6-4cf7-b3b7-b773392dd7f2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "300/300 [==============================] - 17s 56ms/step - loss: 0.1411 - sparse_categorical_accuracy: 0.9566 - val_loss: 0.0453 - val_sparse_categorical_accuracy: 0.9856\n",
            "Epoch 2/5\n",
            "300/300 [==============================] - 5s 16ms/step - loss: 0.0342 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.0343 - val_sparse_categorical_accuracy: 0.9888\n",
            "Epoch 3/5\n",
            "300/300 [==============================] - 4s 14ms/step - loss: 0.0192 - sparse_categorical_accuracy: 0.9935 - val_loss: 0.0460 - val_sparse_categorical_accuracy: 0.9860\n",
            "Epoch 4/5\n",
            "300/300 [==============================] - 4s 14ms/step - loss: 0.0124 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.0379 - val_sparse_categorical_accuracy: 0.9884\n",
            "Epoch 5/5\n",
            "300/300 [==============================] - 4s 15ms/step - loss: 0.0098 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.0456 - val_sparse_categorical_accuracy: 0.9852\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa2393eb220>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9dyeKqaQMWFq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}